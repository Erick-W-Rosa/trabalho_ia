ğŸ“˜ RELATÃ“RIO â€“ ComparaÃ§Ã£o de Modelos de Machine Learning (SVM, Random Forest, KNN)

Dataset: Iris Dataset â€“ scikit-learn

Aluno: Erick William da Rosa

ğŸ§© 1. IntroduÃ§Ã£o

O objetivo deste trabalho Ã© comparar o desempenho de trÃªs algoritmos clÃ¡ssicos de Machine Learning supervisionado aplicados ao dataset Iris:

- SVM (Support Vector Machine)

- Random Forest

- KNN (K-Nearest Neighbors)

Todos os modelos foram implementados utilizando Python e as bibliotecas:

- pandas

- matplotlib

- scikit-learn

O conjunto de dados Iris Ã© composto por 150 amostras de flores, divididas igualmente em trÃªs classes:

- Setosa

- Versicolor

- Virginica

Cada amostra possui quatro caracterÃ­sticas numÃ©ricas:

- Comprimento da sÃ©pala

- Largura da sÃ©pala

- Comprimento da pÃ©tala

- Largura da pÃ©tala

Os dados foram divididos em:

- 70% para treino

- 30% para teste

- Em divisÃ£o estratificada (mantendo a proporÃ§Ã£o das classes)

ğŸ§ª 2. Resultados Obtidos

A seguir estÃ£o os resultados extraÃ­dos diretamente das execuÃ§Ãµes dos trÃªs modelos.

ğŸ”µ 2.1 SVM (Support Vector Machine)
AcurÃ¡cia: 0.9556 (95,56%)
Matriz de ConfusÃ£o

- Acertou todas as instÃ¢ncias da classe Setosa

- Errou 1 amostra de Versicolor, classificando como Virginica

Resumo

- Ã“timo desempenho geral

- Forte separaÃ§Ã£o entre classes

- Poucos erros em classes similares (Versicolor x Virginica)

ğŸŒ² 2.2 Random Forest
AcurÃ¡cia: 0.8889 (88,89%)
Matriz de ConfusÃ£o

- Acertou todas as Setosa

- Teve mais erros entre Versicolor e Virginica, comum em modelos baseados em Ã¡rvores por causa da variaÃ§Ã£o dos splits

Resumo

- Modelo rÃ¡pido de treinar

- Erros maiores em classes com fronteiras suaves

- Desempenho geral inferior ao SVM e KNN neste dataset

ğŸŸ¢ 2.3 KNN (K-Nearest Neighbors)
AcurÃ¡cia: 0.9778 (97,78%)
Matriz de ConfusÃ£o

- Acertou praticamente todas as amostras

- Apenas 1 erro entre Versicolor e Virginica

Resumo

- Melhor desempenho entre todos os modelos

- K=5 funcionou muito bem para este dataset

- Simples, porÃ©m altamente eficaz quando os dados estÃ£o limpos e bem distribuÃ­dos

ğŸ“Š 3. ComparaÃ§Ã£o Direta Entre os Modelos
Modelo	AcurÃ¡cia	Erros Principais
KNN	97,78%	1 erro entre classes vizinhas
SVM	95,56%	1 erro Versicolor/Virginica
Random Forest	88,89%	4 erros Virginica â†’ Versicolor
ğŸ“Œ InterpretaÃ§Ã£o:

- KNN foi o melhor modelo no conjunto Iris.
    - O dataset Ã© pequeno e bem separado â†’ favorece classificadores baseados em distÃ¢ncia.

- SVM teve desempenho excelente, ficando muito prÃ³ximo do KNN.

- Random Forest teve o pior desempenho, porÃ©m ainda acima de 88%.
    - Ãrvores podem ter dificuldades em datasets com fronteiras muito suaves.

ğŸ§  4. ConclusÃµes

Com base nos experimentos realizados:

- O KNN mostrou-se o algoritmo mais preciso neste dataset, beneficiado pela distribuiÃ§Ã£o bem definida das classes.

- O SVM tambÃ©m apresentou excelente performance, sendo eficiente para fronteiras complexas.

- O Random Forest, apesar de bom, teve mais dificuldade em diferenciar as espÃ©cies Versicolor e Virginica.

ğŸ“Œ ConsideraÃ§Ãµes finais:

- Para bancos de dados pequenos e bem separados: KNN Ã© extremamente eficiente.

- Para dados maiores e mais complexos: SVM costuma ter melhor escalabilidade.

- Random Forest Ã© Ã³timo por padrÃ£o, mas nÃ£o foi o ideal neste cenÃ¡rio especÃ­fico.
